{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(__file__).resolve().parents[1] if \"__file__\" in globals() else Path.cwd().parent\n",
    "sys.path.append(str(PROJECT_ROOT))           \n",
    "sys.path.append(str(PROJECT_ROOT / \"src\"))   \n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(\"PYTHONPATH patched:\", sys.path[-2:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "TARGET = \"Survived\" \n",
    "df_raw = pd.read_csv('../data/raw/Titanic-Dataset.csv')\n",
    "X = df_raw.drop(columns=[TARGET])\n",
    "y = df_raw[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "cat_cols = [\"Sex\", \"Pclass\", \"Embarked\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing import build_preprocessing\n",
    "\n",
    "preprocessing = build_preprocessing(num_cols, cat_cols, remainder=\"drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "full_pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessing),\n",
    "    (\"model\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "full_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Define Stratified K-Fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Get cross-validated predictions\n",
    "y_pred = cross_val_predict(full_pipeline, X_train, y_train, cv=skf)\n",
    "\n",
    "# Check if the model has a decision function\n",
    "hasattr(full_pipeline, \"decision_function\") #True\n",
    "hasattr(full_pipeline, \"predict_proba\") #True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cross-validated decision function scores\n",
    "oof_proba = cross_val_predict(full_pipeline, X_train, y_train, cv=skf, method=\"predict_proba\")[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "prec, rec, f1 = precision_score(y_train, y_pred), recall_score(y_train, y_pred), f1_score(y_train, y_pred)\n",
    "print(f\"Precision: {prec:.4f}, Recall: {rec:.4f}, F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "# Compute precision-recall curve\n",
    "precision, recall, _ = precision_recall_curve(y_train, oof_proba)\n",
    "\n",
    "# Compute Area Under the Curve (AUC) for PR curve\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, label=f\"PR Curve (AUC = {pr_auc:.2f})\", color=\"blue\")\n",
    "plt.fill_between(recall, precision, alpha=0.2, color=\"blue\")  # Shade the area under the curve\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_train, oof_proba)\n",
    "\n",
    "# Compute Area Under the Curve (AUC) for ROC curve\n",
    "roc_auc = roc_auc_score(y_train, oof_proba)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.2f})\", color=\"blue\", linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Random Guess\")  # Diagonal line\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Build PR curve points from OOF probabilities\n",
    "precision, recall, thresholds = precision_recall_curve(y_train, oof_proba)\n",
    "\n",
    "# Extend thresholds to match precision and recall lengths\n",
    "thr_ext = np.r_[0.0, thresholds] \n",
    "print(len(precision), len(recall), len(thr_ext))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.choose_threshold import choose_threshold\n",
    "\n",
    "chosen_thr, strategy, metrics = choose_threshold(\n",
    "    oof_proba=oof_proba,\n",
    "    y_train=y_train,\n",
    "    precision=precision,\n",
    "    recall=recall,\n",
    "    thresholds=thresholds,\n",
    "    target_precision=0.85\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "from src.evaluate_metrics import evaluate_metrics\n",
    "\n",
    "# Save the chosen threshold\n",
    "Path(\"../reports\").mkdir(parents=True, exist_ok=True)\n",
    "np.save(\"../reports/threshold.npy\", np.array([chosen_thr]))\n",
    "\n",
    "metrics = evaluate_metrics(oof_proba, chosen_thr, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Consistent seaborn style\n",
    "sns.set(context=\"notebook\", style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_baseline = 0.50\n",
    "\n",
    "# Predictions @ thresholds\n",
    "oof_pred_050 = (oof_proba >= thr_baseline).astype(int)\n",
    "oof_pred_thr = (oof_proba >= chosen_thr).astype(int)\n",
    "\n",
    "cm_050 = confusion_matrix(y_train, oof_pred_050)\n",
    "cm_thr = confusion_matrix(y_train, oof_pred_thr)\n",
    "\n",
    "# Print raw confusion matrices\n",
    "print(\"Confusion Matrix OOF @0.50 :\")\n",
    "print(cm_050)\n",
    "\n",
    "print(\"\\nConfusion Matrix OOF @chosen_thr :\")\n",
    "print(cm_thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a copy of PR curve but with points highlighted at both thresholds.\n",
    "prec, rec, thr = precision_recall_curve(y_train, oof_proba)\n",
    "thr_ext = np.r_[0.0, thr]\n",
    "\n",
    "# Helper: nearest index on the curve to a given threshold value\n",
    "def nearest_idx_to_threshold(threshold_value, thr_extended):\n",
    "    return int(np.argmin(np.abs(thr_extended - threshold_value)))\n",
    "\n",
    "idx_050 = nearest_idx_to_threshold(thr_baseline, thr_ext)\n",
    "idx_thr = nearest_idx_to_threshold(chosen_thr, thr_ext)\n",
    "\n",
    "plt.figure(figsize=(6, 4.5))\n",
    "plt.plot(rec, prec, label=\"PR (OOF)\")\n",
    "\n",
    "# Mark baseline point\n",
    "plt.scatter(rec[idx_050], prec[idx_050], s=60, marker=\"o\", label=f\"@0.50  (P={prec[idx_050]:.2f}, R={rec[idx_050]:.2f})\")\n",
    "\n",
    "# Mark chosen threshold point\n",
    "plt.scatter(rec[idx_thr], prec[idx_thr], s=70, marker=\"s\", label=f\"@{chosen_thr:.3f} (P={prec[idx_thr]:.2f}, R={rec[idx_thr]:.2f})\")\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"PR curve (OOF) with threshold markers\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
